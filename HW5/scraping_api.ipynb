{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a871d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in /Users/3aotk/micromamba/envs/hw3/lib/python3.13/site-packages (7.8.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in /Users/3aotk/micromamba/envs/hw3/lib/python3.13/site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in /Users/3aotk/micromamba/envs/hw3/lib/python3.13/site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /Users/3aotk/micromamba/envs/hw3/lib/python3.13/site-packages (from praw) (1.9.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /Users/3aotk/micromamba/envs/hw3/lib/python3.13/site-packages (from prawcore<3,>=2.4->praw) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/3aotk/micromamba/envs/hw3/lib/python3.13/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/3aotk/micromamba/envs/hw3/lib/python3.13/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/3aotk/micromamba/envs/hw3/lib/python3.13/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/3aotk/micromamba/envs/hw3/lib/python3.13/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "# Install praw\n",
    "# PRAW (Python Reddit API Wrapper) is the most common, well-documented library for accessing Reddit data\n",
    "\n",
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5347d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import os\n",
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Authenticate with Reddit API using environment variables\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.environ.get(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.environ.get(\"REDDIT_CLIENT_SECRET\"),\n",
    "    user_agent=os.environ.get(\"REDDIT_USER_AGENT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a subreddit\n",
    "subreddit = reddit.subreddit(\"dataisbeautiful\")  # Change as needed\n",
    "\n",
    "# Collect the 100 most popular posts from 'hot'\n",
    "posts_data = []\n",
    "for post in subreddit.hot(limit=100):\n",
    "    posts_data.append({\n",
    "        \"title\": post.title,\n",
    "        \"score\": post.score,\n",
    "        \"num_comments\": post.num_comments,\n",
    "        \"author\": str(post.author),\n",
    "        \"created_utc\": post.created_utc,\n",
    "        \"url\": post.url\n",
    "    })\n",
    "\n",
    "# Store in a pandas DataFrame\n",
    "df = pd.DataFrame(posts_data)\n",
    "\n",
    "# Preview and save the data\n",
    "print(df.head())\n",
    "df.to_csv(\"reddit_data.csv\", index=False)\n",
    "print(\"Data saved to reddit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.environ[\"REDDIT_CLIENT_ID\"],\n",
    "    client_secret=os.environ[\"REDDIT_CLIENT_SECRET\"],\n",
    "    user_agent=os.environ[\"REDDIT_USER_AGENT\"]\n",
    ")\n",
    "\n",
    "subreddit = reddit.subreddit(\"dataisbeautiful\")\n",
    "\n",
    "posts_data = []\n",
    "for post in subreddit.hot(limit=100):\n",
    "    posts_data.append({\n",
    "        \"title\": post.title,\n",
    "        \"score\": post.score,\n",
    "        \"num_comments\": post.num_comments,\n",
    "        \"author\": str(post.author),\n",
    "        \"created_utc\": post.created_utc,\n",
    "        \"url\": post.url\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(posts_data)\n",
    "print(df.head())\n",
    "df.to_csv(\"reddit_data.csv\", index=False)\n",
    "print(\"✅ Data saved to reddit_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77253d27",
   "metadata": {},
   "source": [
    "### Each Reddit post includes multiple attributes. In this example, I collected:\n",
    "\n",
    "- **title:** post title\n",
    "- **score:** upvotes minus downvotes\n",
    "- **num_comments:** number of comments\n",
    "- **author:** username of poster\n",
    "- **created_utc:** time created (UNIX timestamp)\n",
    "- **url:** link to the post\n",
    "\n",
    "Note: This dataset contains 6 attributes for at least 100 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09590f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af669bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose a subreddit\n",
    "subreddit = reddit.subreddit(\"dataisbeautiful\")\n",
    "\n",
    "# Collect comments from chosen subreddit\n",
    "\n",
    "comments = []\n",
    "for comment in subreddit.comments(limit=120):  # Slightly above 100 to ensure valid ones\n",
    "    comments.append({\n",
    "        \"comment_id\": comment.id,\n",
    "        \"body\": comment.body,\n",
    "        \"score\": comment.score,\n",
    "        \"author\": str(comment.author),\n",
    "        \"created_utc\": comment.created_utc,\n",
    "        \"link_id\": comment.link_id\n",
    "    })\n",
    "\n",
    "\n",
    "# Create dataframe\n",
    "\n",
    "df_comments = pd.DataFrame(comments)\n",
    "print(df_comments.head())\n",
    "df_comments.to_csv(\"reddit_comments.csv\", index=False)\n",
    "print(\"✅ Saved 100+ comments to reddit_comments.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef83c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
